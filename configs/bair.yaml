# Experiment name
name: "bair"

# Dataset parameters
data:
  data_root: "./data/BAIR_h5" # path to the dataset folder
  input_size: 256
  crop_size: 256
  frames_per_sample: 16
  skip_frames: 0
  random_horizontal_flip: False
  aug: False
  albumentations: True

# Parameters of the model
model:
  # Defines the sigma min
  sigma: 0.0000001
  # Number of frames that are simultaneously denoised
  num_target_frames: 3
  # Number of context frames
  num_context_frames: 1
  # Randomized training params
  no_context_p: 0.5
  no_reference_p: 0.2
  # Probability to select DINO features
  feats_select_prob: 0.1
  # Feature encoder to use
  feature_backbone: "dino"
  # Number of DINO layers to use
  num_dino_layers: 2
  dino_version: "dinov2_vitb14"

  # Parameters for vector field regressor
  vector_field_regressor:
    state_size: 8
    state_res: [16, 16]
    inner_dim: 768
    depth: 9
    mid_depth: 5
    fc_dim: 3072
    num_heads: 8
    dropout: 0.05
    # New params
    max_relative_position: 8
    masking_ratio: 0.4
    causal: False

  # Parameters for the autoencoder
  autoencoder:
    # The architecture of the autoencoder [ours, ldm-vq, ldm-kl]
    type: "ldm-vq"
    config: "f16"
    ckpt_path: "./ae_checkpoints/bair.pth"  # path to the checkpoint

# Parameters for the training
training:
  # Parameters for batch building
  batching:
    batch_size: 16
    num_workers: 7

  # Parameters for the optimizer
  optimizer:
    learning_rate: 0.0001
    weight_decay: 0.000005

    num_warmup_steps: 5000
    num_training_steps: 100000

  # Number of observations in the sequence
  num_observations: 16
  # Number of frames to use as initial conditioning
  condition_frames: 1
  # Nuber of frames to generate
  frames_to_generate: 15

  # Parameters for loss weighting
  loss_weights:
    flow_matching_loss: 1.0
